{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis for Mobile Phones Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from textblob import TextBlob, Word, Blobber\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob.taggers import NLTKTagger\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_SaveData(myList,filename):\n",
    "    np.array(myList).dump(open(filename+'.npy', 'wb'))\n",
    "    \n",
    "def np_LoadData(filename):\n",
    "    myArray = np.load(open(filename+'.npy', 'rb'))\n",
    "    return myArray\n",
    "\n",
    "def SaveDictionary(Dic,DicName):\n",
    "    #This saves all the key-value pair dictionaries\n",
    "    pickle_out = open(DicName,\"wb\")\n",
    "    pickle.dump(Dic, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "def ReadDictionary(DicName):\n",
    "    pickle_in = open(DicName,\"rb\")\n",
    "    diction = pickle.load(pickle_in)\n",
    "    return diction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Dictionary Directory to load Data >>\n",
      "\tC:\\Users\\Asad\\Python\\CodePython\\FYP\\GsmScrapper\\Dictionary\n",
      "\tDocs Loaded\n",
      "Returning to Main Directory\n",
      "\tC:\\Users\\Asad\\Python\\CodePython\\FYP\\GsmScrapper\n"
     ]
    }
   ],
   "source": [
    "path=os.getcwd()\n",
    "x=path+\"\\\\Dictionary\\\\\"\n",
    "os.chdir(x)\n",
    "print (\"Entering Dictionary Directory to load Data >>\")\n",
    "print (\"\\t\"+os.getcwd())\n",
    "Docs=np_LoadData(\"Docs\")\n",
    "print (\"\\t\"+\"Docs Loaded\")\n",
    "os.chdir(path)\n",
    "print (\"Returning to Main Directory\")\n",
    "print (\"\\t\"+os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For every phone we have to calculate a Rating of the phone based on the Sentiment Analysis of Comments. So for each phone, we will calculate a score of rating out of 100% based on all comments for that phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LabeledComments(Docs):\n",
    "    Comment=[]\n",
    "    Sentiment=[]\n",
    "    counterpos=0\n",
    "    counterneg=0\n",
    "    counter=0\n",
    "    Files=len(Docs)\n",
    "    for Phones in Docs:\n",
    "        for Comments in Phones:\n",
    "            analysis= TextBlob(Comments)\n",
    "            if(analysis.sentiment.polarity!=0.0):\n",
    "                if(analysis.sentiment.polarity>0.0):\n",
    "                    #Positive\n",
    "                    if(counterpos<=80000):\n",
    "                        counterpos+=1\n",
    "                        Comment.append(Comments)\n",
    "                        Sentiment.append(\"Positive\")\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    #Negative\n",
    "                    Comment.append(Comments)\n",
    "                    Sentiment.append(\"Negative\")\n",
    "                    counterneg+=1\n",
    "        if(counterneg>80000):\n",
    "            break\n",
    "        print(\"Progress {:2.1%}\".format(counter / Files), end=\"\\r\")\n",
    "        counter+=1\n",
    "    return Comment,Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 92.4%\r"
     ]
    }
   ],
   "source": [
    "Comment,Sentiment=LabeledComments(Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative to Positive Comment Ratio is:  80001 : 80017\n"
     ]
    }
   ],
   "source": [
    "cn=0\n",
    "cp=0\n",
    "for text in Sentiment:\n",
    "    if (text=='Positive'):\n",
    "        cp+=1\n",
    "    else:\n",
    "        cn+=1\n",
    "print (\"Negative to Positive Comment Ratio is: \",cp,\":\",cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160018 160018\n"
     ]
    }
   ],
   "source": [
    "print (len(Comment),len(Sentiment))\n",
    "data = pd.DataFrame({'Text':Comment, 'Sentiment':Sentiment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160002\n",
      "160034\n"
     ]
    }
   ],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: x.lower())\n",
    "data['Text'] = data['Text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "print(data[ data['Sentiment'] == 'Positive'].size)\n",
    "print(data[ data['Sentiment'] == 'Negative'].size)\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_features = 2000\n",
    "tokenizer = Tokenizer(nb_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['Text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['Text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2eb941c4fcc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlstm_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m196\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmymodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmymodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_U\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_W\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "mymodel = Sequential()\n",
    "mymodel.add(embeddings(max_features,embed_dim,input_length = X.shape[1], dropout=0.2))\n",
    "mymodel.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))\n",
    "mymodel.add(Dense(2,activation='softmax'))\n",
    "mymodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(mymodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(data['Sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, nb_epoch = 7, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X_validate)):\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
